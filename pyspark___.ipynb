{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LoCk7SgRrFuP",
        "QkvG7CGo1BgF",
        "YV16sPAT04lt",
        "cdANBnd70u-E",
        "ziIgaC_cXx8S",
        "1bbYGM8MX3zO",
        "9nO5mhnwPozH",
        "uBXdq3jqPwur"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIA23YgbXKJd"
      },
      "source": [
        "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바가상머신상의 오브젝트들을 접근할 수 있게 해준다. Local Standalone Spark을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "168f0852-16a4-4982-b52d-48e67465ed61"
      },
      "source": [
        "!pip install pyspark==3.5.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.5.3\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark==3.5.3) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=3dcfd3de2281de53aeb967297f09d1f884cbcc6d589042df6225488a0dc7de96\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/f5/c0/947e2c0942b361ffe58651f36bd7f13772675b3863fd63d1b1\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.4\n",
            "    Uninstalling pyspark-3.5.4:\n",
            "      Successfully uninstalled pyspark-3.5.4\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_eTGrvXlDw"
      },
      "source": [
        "**Spark Session**을 하나 만든다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark Unit Test\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3-geospatial.s3-us-west-2.amazonaws.com/name_gender.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKrMnuGVK77P",
        "outputId": "1986c3fe-052a-444f-f37f-544a7a063077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-10 08:09:44--  https://s3-geospatial.s3-us-west-2.amazonaws.com/name_gender.csv\n",
            "Resolving s3-geospatial.s3-us-west-2.amazonaws.com (s3-geospatial.s3-us-west-2.amazonaws.com)... 52.218.224.249, 3.5.82.158, 3.5.84.13, ...\n",
            "Connecting to s3-geospatial.s3-us-west-2.amazonaws.com (s3-geospatial.s3-us-west-2.amazonaws.com)|52.218.224.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 997 [text/csv]\n",
            "Saving to: ‘name_gender.csv’\n",
            "\n",
            "\rname_gender.csv       0%[                    ]       0  --.-KB/s               \rname_gender.csv     100%[===================>]     997  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-10 08:09:44 (14.5 MB/s) - ‘name_gender.csv’ saved [997/997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\", True).csv(\"name_gender.csv\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZhdS0i7LZEc",
        "outputId": "29ca3a15-be31-435b-ead7-27d96e88d18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFDiqDcLeq7",
        "outputId": "084e59f3-f445-44b3-b4d9-909fcc2d9da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"namegender\")\n",
        "spark.sql(\"SELECT gender, COUNT(1) count FROM namegender GROUP BY 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmbJXYQ0LlUB",
        "outputId": "e7102dca-f5ac-4376-ff08-e41e40943dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|gender|count|\n",
            "+------+-----+\n",
            "|     F|   65|\n",
            "|     M|   28|\n",
            "|Unisex|    7|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import *\n",
        "import pandas as pd\n",
        "\n",
        "# Define the UDF\n",
        "@pandas_udf(StringType())\n",
        "def upper_udf_f(s: pd.Series) -> pd.Series:\n",
        "    return s.str.upper()\n",
        "\n",
        "upperUDF = spark.udf.register(\"upper_udf\", upper_udf_f)"
      ],
      "metadata": {
        "id": "-Y0CL9EpMO-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_gender(spark, file_path):\n",
        "    return spark.read.option(\"header\", True).csv(file_path)\n",
        "\n",
        "def get_gender_count(spark, df, field_to_count):\n",
        "    df.createOrReplaceTempView(\"namegender_test\")\n",
        "    return spark.sql(f\"SELECT {field_to_count}, COUNT(1) count FROM namegender_test GROUP BY 1\")"
      ],
      "metadata": {
        "id": "dRLF06SILaP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_gender(spark, \"name_gender.csv\")\n",
        "get_gender_count(spark, df, \"gender\").show()\n",
        "df.select(upperUDF(\"name\").alias(\"NAME\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WT4JmtMsn4",
        "outputId": "5ee24803-8e43-4e6d-d1bf-aefc943dcc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|gender|count|\n",
            "+------+-----+\n",
            "|     F|   65|\n",
            "|     M|   28|\n",
            "|Unisex|    7|\n",
            "+------+-----+\n",
            "\n",
            "+----------+\n",
            "|      NAME|\n",
            "+----------+\n",
            "|  ADALEIGH|\n",
            "|     AMRYN|\n",
            "|    APURVA|\n",
            "|    ARYION|\n",
            "|    ALIXIA|\n",
            "|ALYSSAROSE|\n",
            "|    ARVELL|\n",
            "|     AIBEL|\n",
            "|   ATIYYAH|\n",
            "|     ADLIE|\n",
            "|    ANYELY|\n",
            "|    AAMONI|\n",
            "|     AHMAN|\n",
            "|    ARLANE|\n",
            "|   ARMONEY|\n",
            "|   ATZHIRY|\n",
            "| ANTONETTE|\n",
            "|   AKEELAH|\n",
            "| ABDIKADIR|\n",
            "|    ARINZE|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(upperUDF(\"name\").alias(\"NAME\")).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFg5z8O-Qv54",
        "outputId": "95e10343-ace2-4dc9-8e09-9b5de2ab286a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(NAME='ADALEIGH'),\n",
              " Row(NAME='AMRYN'),\n",
              " Row(NAME='APURVA'),\n",
              " Row(NAME='ARYION'),\n",
              " Row(NAME='ALIXIA'),\n",
              " Row(NAME='ALYSSAROSE'),\n",
              " Row(NAME='ARVELL'),\n",
              " Row(NAME='AIBEL'),\n",
              " Row(NAME='ATIYYAH'),\n",
              " Row(NAME='ADLIE'),\n",
              " Row(NAME='ANYELY'),\n",
              " Row(NAME='AAMONI'),\n",
              " Row(NAME='AHMAN'),\n",
              " Row(NAME='ARLANE'),\n",
              " Row(NAME='ARMONEY'),\n",
              " Row(NAME='ATZHIRY'),\n",
              " Row(NAME='ANTONETTE'),\n",
              " Row(NAME='AKEELAH'),\n",
              " Row(NAME='ABDIKADIR'),\n",
              " Row(NAME='ARINZE'),\n",
              " Row(NAME='ARSHAUN'),\n",
              " Row(NAME='ALEXANDRO'),\n",
              " Row(NAME='AYRIAUNA'),\n",
              " Row(NAME='AQIB'),\n",
              " Row(NAME='ALLEYA'),\n",
              " Row(NAME='AAVAH'),\n",
              " Row(NAME='ANESTI'),\n",
              " Row(NAME='ADALAIDE'),\n",
              " Row(NAME='ANALENA'),\n",
              " Row(NAME='ALAEYAH'),\n",
              " Row(NAME='ALBENA'),\n",
              " Row(NAME='AIMI'),\n",
              " Row(NAME='ADWAITH'),\n",
              " Row(NAME='ARKADY'),\n",
              " Row(NAME='ASTYN'),\n",
              " Row(NAME='ADELEE'),\n",
              " Row(NAME='AGATA'),\n",
              " Row(NAME='ALEGNA'),\n",
              " Row(NAME='ALTAN'),\n",
              " Row(NAME='AHNALEIGH'),\n",
              " Row(NAME='ALGIE'),\n",
              " Row(NAME='ASHANTI'),\n",
              " Row(NAME='AISLYN'),\n",
              " Row(NAME='ADALEINE'),\n",
              " Row(NAME='ANTHNOY'),\n",
              " Row(NAME='ALGERNON'),\n",
              " Row(NAME='AERYONA'),\n",
              " Row(NAME='ADRINNE'),\n",
              " Row(NAME='ADDELL'),\n",
              " Row(NAME='AVRIL'),\n",
              " Row(NAME='AHNI'),\n",
              " Row(NAME='AIMON'),\n",
              " Row(NAME='ADOLPHO'),\n",
              " Row(NAME='AHUVA'),\n",
              " Row(NAME='AURIELLE'),\n",
              " Row(NAME='AVEANA'),\n",
              " Row(NAME='ALIYIA'),\n",
              " Row(NAME='ALESANDER'),\n",
              " Row(NAME='ADNREA'),\n",
              " Row(NAME='ANJAE'),\n",
              " Row(NAME='ALVINE'),\n",
              " Row(NAME='ADORAH'),\n",
              " Row(NAME='ADLEMI'),\n",
              " Row(NAME='ALESI'),\n",
              " Row(NAME='ALONTAE'),\n",
              " Row(NAME='ANTONNY'),\n",
              " Row(NAME='ADARAH'),\n",
              " Row(NAME='AYREANNA'),\n",
              " Row(NAME='ANTYON'),\n",
              " Row(NAME='ANDIA'),\n",
              " Row(NAME='ASHLA'),\n",
              " Row(NAME='ASPYN'),\n",
              " Row(NAME='ANTWANETT'),\n",
              " Row(NAME='AUNDREIA'),\n",
              " Row(NAME='AUDELLA'),\n",
              " Row(NAME='AMARI'),\n",
              " Row(NAME='ARSHA'),\n",
              " Row(NAME='ARICELLA'),\n",
              " Row(NAME='ADAN'),\n",
              " Row(NAME='APASRA'),\n",
              " Row(NAME='ALAYSHA'),\n",
              " Row(NAME='ANDERSON'),\n",
              " Row(NAME='AURELIUS'),\n",
              " Row(NAME='AERIAL'),\n",
              " Row(NAME='AVERLEIGH'),\n",
              " Row(NAME='ASLEAN'),\n",
              " Row(NAME='ARNIESHA'),\n",
              " Row(NAME='ASYANA'),\n",
              " Row(NAME='ANNJANE'),\n",
              " Row(NAME='AMABELLA'),\n",
              " Row(NAME='AUSTINJOHN'),\n",
              " Row(NAME='ARLOWEEN'),\n",
              " Row(NAME='ALULA'),\n",
              " Row(NAME='ANEMONE'),\n",
              " Row(NAME='AMORINA'),\n",
              " Row(NAME='ANUREET'),\n",
              " Row(NAME='ARRIC'),\n",
              " Row(NAME='ANTONNE'),\n",
              " Row(NAME='ALYRE'),\n",
              " Row(NAME='ANNAISE')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 유닛 테스트 코드 붙여보기"
      ],
      "metadata": {
        "id": "kO6tHzLzLR8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unittest import TestCase\n",
        "\n",
        "# 일반적으로는 아래 함수가 정의된 모듈을 임포트하고 그걸 테스트\n",
        "#  - upper_udf_f\n",
        "#  - load_gender\n",
        "#  - get_gender_count\n",
        "\n",
        "class UtilsTestCase(TestCase):\n",
        "    spark = None\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls) -> None:\n",
        "        cls.spark = SparkSession.builder \\\n",
        "            .appName(\"Spark Unit Test\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "    def test_datafile_loading(self):\n",
        "        sample_df = load_gender(self.spark, \"name_gender.csv\")\n",
        "        result_count = sample_df.count()\n",
        "        self.assertEqual(result_count, 100, \"Record count should be 100\")\n",
        "\n",
        "    def test_gender_count(self):\n",
        "        sample_df = load_gender(self.spark, \"name_gender.csv\")\n",
        "        count_list = get_gender_count(self.spark, sample_df, \"gender\").collect()\n",
        "        count_dict = dict()\n",
        "        for row in count_list:\n",
        "            count_dict[row[\"gender\"]] = row[\"count\"]\n",
        "        self.assertEqual(count_dict[\"F\"], 65, \"Count for F should be 65\")\n",
        "        self.assertEqual(count_dict[\"M\"], 28, \"Count for M should be 28\")\n",
        "        self.assertEqual(count_dict[\"Unisex\"], 7, \"Count for Unisex should be 7\")\n",
        "\n",
        "    def test_upper_udf(self):\n",
        "        test_data = [\n",
        "            { \"name\": \"John Kim\" },\n",
        "            { \"name\": \"Johnny Kim\"},\n",
        "            { \"name\": \"1234\" }\n",
        "        ]\n",
        "        expected_results = [ \"JOHN KIM\", \"JOHNNY KIM\", \"1234\" ]\n",
        "\n",
        "        upperUDF = self.spark.udf.register(\"upper_udf\", upper_udf_f)\n",
        "        test_df = self.spark.createDataFrame(test_data)\n",
        "        names = test_df.select(\"name\", upperUDF(\"name\").alias(\"NAME\")).collect()\n",
        "        results = []\n",
        "        for name in names:\n",
        "            results.append(name[\"NAME\"])\n",
        "        self.assertCountEqual(results, expected_results)\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls) -> None:\n",
        "        cls.spark.stop()"
      ],
      "metadata": {
        "id": "LeGWFXXpIpOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "HFE9zkakGA55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5eb18f1-da84-4285-db70-63279f3b9c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_datafile_loading (__main__.UtilsTestCase.test_datafile_loading) ... ok\n",
            "test_gender_count (__main__.UtilsTestCase.test_gender_count) ... ok\n",
            "test_upper_udf (__main__.UtilsTestCase.test_upper_udf) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 6.357s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7c726dbf4050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}